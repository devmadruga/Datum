# Datum

Ol√° üëã Datum. Tudo bem com voc√™s? 

Eu sou o Anderson Madruga ([Linkedin](https://www.linkedin.com/in/anderson-madruga-dos-santos/)) e por aqui est√° tudo bem! :blush:

Neste reposit√≥rio voc√™s encontrar√£o informa√ß√µes a respeito do meu teste t√©cnico para a vaga de Desenvolvedor Python (job description compat√≠vel com Engenheiro de Dados).

## 1. DataSet

Para realizar o teste t√©cnico, escolhi o [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce). O diagrama de entidade e relacionamento foi fornecido:

![Descri√ß√£o da imagem](auxiliares/er_kaggle.png)


## 2. Camada Bronze

[Arquivos da camada bronze](./bronze)

Nesta camada, um arquivo .ipynb que:
1. Faz a autentica√ß√£o na api do kaggle, com minhas informa√ß√µes de usu√°rio.
2. Faz o check da watermark que registra a data de ultima atualiza√ß√£o do dataset no kaggle.
3. Faz o check dos arquivos na camada bronze no dbfs.

Basicamente, 
* se o **dataset n√£o consta atualiza√ß√£o** e j√° **estamos com os arquivos .csv no dbfs (camada bronze)**, o job falha e as camadas silver e gold n√£o s√£o processada.

* j√° se o **dataset sofreu atualiza√ß√£o no kaggle** ou se "existem arquivos faltantes na camada bronze do dbfs**, o job √© executado por completo.

Uma notifica√ß√£o √© enviada por email caso o job rode por completo. O normal, aqui, √© n√£o executar essa pipeline completa, j√° que o dataset sofre poucas atualiza√ß√µes. Trigger, notifica√ß√£o e as tasks do workflow:

![Schedule e Job Notiication](auxiliares/databricks_schedule_jobnotifications.png)

![Workflow tasks](auxiliares/databricks_workflow_tasks.png)

## 3. Camada Silver
[Arquivos da camada silver](./silver)

Na camada silver eu crio dataframes a partir dos dados .csv da camada bronze. 

Ent√£o, defino schema, fa√ßo transforma√ß√µes b√°sicas (como a que voc√™s pediram -> adi√ß√£o de colunas calculadas) e exporto os dados em delta para a camada silver. Todos os notebooks da camada silver seguem esta l√≥gica.

## 4. Camada Gold
[Arquivos da camada gold](./gold)

Antes de implementar a camada gold, defini 5 informa√ß√µes que eu gostaria de obter do dataset. S√£o elas:

1. Uma lista dos produtos comprados aos pares e a quantidade de vezes que isto acontece.
2. Total de vendas (R$) para cada forma de pagamento.
3. Total de vendas (R$) por Estado.
4. Total de vendas (R$) por m√™s e por dia.
5. Um estudo sobre a diferen√ßa na data de entrega real e a data de entrega prevista pelo algoritmo da Olist.

`Observa√ß√£o:` Tantas outras informa√ß√µes importantes para o neg√≥cio poderiam ser obtidas deste dataset.

Ent√£o, com os objetivos definidos, os notebooks da camada gold seguem a l√≥gica:

> importamos os dados da camada silver -> fazemos os tratamentos necess√°rios (valores nulos ou vazios, adicioarmos colunas calculadas, agrega√ß√µes, somas, counts, joins e etc) -> exportamos os dados pertinentes no formato delta para a camada gold -> criamos uma DELTA TABLE com os dados pertinentes

Um objetivo aqui na camada gold √© o de entregar o dado mais pronto poss√≠vel para an√°lise, para que n√£o tenhamos tratamentos de dados em ferramentas de BI ou mesmo aqui no databricks dentro das sql queries do sql warehouse.

Por fim, voc√™s encontrar√£o nos .ipynb da camada gold, um pouco mais de tratamento de dados e manipula√ß√£o dos dados. Por√©m, ainda s√£o tratamentos de um dataset do kaggle. "A realidade l√° fora √© bastante mais dura do que no kaggle." :grin:

## 5.0 Workflows - Job

O job retorna erro no [KaggleAutenticacao_IngestaoDados.ipynb](./bronze/KaggleAutenticacao_IngestaoDados.ipynb) quando j√° tivermos os arquivos .csv no dbfs **E** estivermos com o dataset atualizado em rela√ß√£o ao kaggle.


![Run failed](auxiliares/job_falha.png)
![Exception](auxiliares/exception.png)
![Exception e Print](auxiliares/exception_print.png)

J√° quanto n√£o temos dados na camada bronze ou o dataset foi atualizao no kaggle, o job tem que rodar por completo. Vou apagar os dados da bronze com "%fs rm -r path" e rodar o job. Percebam o output no final do [KaggleAutenticacao_IngestaoDados.ipynb](./bronze/KaggleAutenticacao_IngestaoDados.ipynb) que indica que o motivo do download √© pela camada bronze n√£o existir no dbfs:

![Mostrando ingest√£o](auxiliares/mostrando_ingestao.png)
![Run succeeded](auxiliares/job_sucesso.png)

## 6.0  SQL Warehouse

Como criei as tabelas delta, usei a Dashboard do Databricks. Observa√ß√£o: Vale lembrar que facilmente poder√≠amos ter feito os gr√°ficos em python e exportado para um arquivo .pdf. Poder√≠maos criar uma nova camada al√©m da gold, que faria os plots e exportaria para o .pdf, compondo um relat√≥rio. 

Aqui, as queries s√£o bastante simples, devido ao trabalho feito na gold:

![Queries](auxiliares/queries.png)


Total sales by payment type

```sql
SELECT 
*
FROM olist.total_sales_by_payment_type
ORDER BY total_sales DESC;
```

Delivery date analyses

```sql
SELECT
delivery_time_diff AS `Desvio de dias na entrega`,
percentage AS `% de Compras`
FROM olist.delivery_date_analyses;
```

Total sales by state

```sql
SELECT *
FROM olist.total_sales_by_state
ORDER BY `total_R$`;
```

Total sales by month by day

```sql
SELECT *
FROM olist.total_sales_by_month_by_day
ORDER BY total_sales DESC;
```

Most common product pair

```sql
SELECT *
FROM olist.most_common_product_pair
ORDER BY freq DESC;
```

Depois de ter configurado as visualiza√ß√µes, embora elas sejam bastante limitadas no Dashboards do Databricks, o .pdf exportado pode ser visto [AQUI](auxiliares/DashboardsDatabricks.pdf). Vale a nota de que, enquanto o gr√°fico de bolhas (3 colunas) faz sentido, aqui no arquivo exportado n√£o faz. :disappointed_relieved:

`Observa√ß√£o:` O export em .pdf n√£o fica nada bom. Eu fiz um v√≠deo mostrando o projeto no meu ambiente do Databricks. Enviei o v√≠deo por email para a Jackeline, mas [AQUI EST√Å O LINK PARA O V√çDEO](https://drive.google.com/file/d/1iamKGzTbAsGNe4pQZNRBzzxJa7vH1qWi/view?usp=sharing).

# 7.0 Considera√ß√µes Finais

Obrigado pela oportunidade e se tiverem qualquer d√∫vida, estou dispon√≠vel para conversarmos. 

:punch:
